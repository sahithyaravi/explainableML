{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "J5P4ugEmiS8G",
    "outputId": "e42ab5c2-a0f4-4db4-a84d-bd1ea21fd32a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu==1.15.0\n",
      "  Using cached tensorflow_gpu-1.15.0-cp37-cp37m-win_amd64.whl (294.5 MB)\n",
      "Collecting absl-py>=0.7.0\n",
      "  Using cached absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
      "Collecting tensorboard<1.16.0,>=1.15.0\n",
      "  Using cached tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
      "Collecting keras-applications>=1.0.8\n",
      "  Using cached Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "Collecting gast==0.2.2\n",
      "  Using cached gast-0.2.2-py3-none-any.whl\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting protobuf>=3.6.1\n",
      "  Using cached protobuf-3.17.3-cp37-cp37m-win_amd64.whl (909 kB)\n",
      "Collecting google-pasta>=0.1.6\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting numpy<2.0,>=1.16.0\n",
      "  Using cached numpy-1.20.3-cp37-cp37m-win_amd64.whl (13.6 MB)\n",
      "Collecting tensorflow-estimator==1.15.1\n",
      "  Using cached tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
      "Collecting wrapt>=1.11.1\n",
      "  Using cached wrapt-1.12.1-cp37-cp37m-win_amd64.whl\n",
      "Collecting grpcio>=1.8.6\n",
      "  Using cached grpcio-1.38.0-cp37-cp37m-win_amd64.whl (3.1 MB)\n",
      "Collecting wheel>=0.26\n",
      "  Using cached wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting astor>=0.6.0\n",
      "  Using cached astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting keras-preprocessing>=1.0.5\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting six>=1.10.0\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting h5py\n",
      "  Using cached h5py-3.2.1-cp37-cp37m-win_amd64.whl (2.7 MB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Collecting setuptools>=41.0.0\n",
      "  Using cached setuptools-57.0.0-py3-none-any.whl (821 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached Werkzeug-2.0.1-py3-none-any.whl (288 kB)\n",
      "Collecting importlib-metadata\n",
      "  Using cached importlib_metadata-4.5.0-py3-none-any.whl (17 kB)\n",
      "Collecting cached-property\n",
      "  Using cached cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting typing-extensions>=3.6.4\n",
      "  Using cached typing_extensions-3.10.0.0-py3-none-any.whl (26 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.4.1-py3-none-any.whl (5.2 kB)\n",
      "Installing collected packages: zipp, typing-extensions, six, numpy, importlib-metadata, cached-property, wheel, werkzeug, setuptools, protobuf, markdown, h5py, grpcio, absl-py, wrapt, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, keras-applications, google-pasta, gast, astor, tensorflow-gpu\n",
      "  Attempting uninstall: zipp\n",
      "    Found existing installation: zipp 3.4.1\n",
      "    Uninstalling zipp-3.4.1:\n",
      "      Successfully uninstalled zipp-3.4.1\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.0\n",
      "    Uninstalling typing-extensions-3.10.0.0:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script wheel.exe is installed in 'C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script markdown_py.exe is installed in 'C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts estimator_ckpt_converter.exe, freeze_graph.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.0\n",
      "    Uninstalling numpy-1.19.0:\n",
      "      Successfully uninstalled numpy-1.19.0\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 4.5.0\n",
      "    Uninstalling importlib-metadata-4.5.0:\n",
      "      Successfully uninstalled importlib-metadata-4.5.0\n",
      "  Attempting uninstall: cached-property\n",
      "    Found existing installation: cached-property 1.5.2\n",
      "    Uninstalling cached-property-1.5.2:\n",
      "      Successfully uninstalled cached-property-1.5.2\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.36.2\n",
      "    Uninstalling wheel-0.36.2:\n",
      "      Successfully uninstalled wheel-0.36.2\n",
      "  Attempting uninstall: werkzeug\n",
      "    Found existing installation: Werkzeug 2.0.1\n",
      "    Uninstalling Werkzeug-2.0.1:\n",
      "      Successfully uninstalled Werkzeug-2.0.1\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 57.0.0\n",
      "    Uninstalling setuptools-57.0.0:\n",
      "      Successfully uninstalled setuptools-57.0.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.17.3\n",
      "    Uninstalling protobuf-3.17.3:\n",
      "      Successfully uninstalled protobuf-3.17.3\n",
      "  Attempting uninstall: markdown\n",
      "    Found existing installation: Markdown 3.3.4\n",
      "    Uninstalling Markdown-3.3.4:\n",
      "      Successfully uninstalled Markdown-3.3.4\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.2.1\n",
      "    Uninstalling h5py-3.2.1:\n",
      "      Successfully uninstalled h5py-3.2.1\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.38.0\n",
      "    Uninstalling grpcio-1.38.0:\n",
      "      Successfully uninstalled grpcio-1.38.0\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 0.12.0\n",
      "    Uninstalling absl-py-0.12.0:\n",
      "      Successfully uninstalled absl-py-0.12.0\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.12.1\n",
      "    Uninstalling wrapt-1.12.1:\n",
      "      Successfully uninstalled wrapt-1.12.1\n",
      "  Attempting uninstall: termcolor\n",
      "    Found existing installation: termcolor 1.1.0\n",
      "    Uninstalling termcolor-1.1.0:\n",
      "      Successfully uninstalled termcolor-1.1.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 1.15.1\n",
      "    Uninstalling tensorflow-estimator-1.15.1:\n",
      "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 1.15.0\n",
      "    Uninstalling tensorboard-1.15.0:\n",
      "      Successfully uninstalled tensorboard-1.15.0\n",
      "  Attempting uninstall: opt-einsum\n",
      "    Found existing installation: opt-einsum 3.3.0\n",
      "    Uninstalling opt-einsum-3.3.0:\n",
      "      Successfully uninstalled opt-einsum-3.3.0\n",
      "  Attempting uninstall: keras-preprocessing\n",
      "    Found existing installation: Keras-Preprocessing 1.1.2\n",
      "    Uninstalling Keras-Preprocessing-1.1.2:\n",
      "      Successfully uninstalled Keras-Preprocessing-1.1.2\n",
      "  Attempting uninstall: keras-applications\n",
      "    Found existing installation: Keras-Applications 1.0.8\n",
      "    Uninstalling Keras-Applications-1.0.8:\n",
      "      Successfully uninstalled Keras-Applications-1.0.8\n",
      "  Attempting uninstall: google-pasta\n",
      "    Found existing installation: google-pasta 0.2.0\n",
      "    Uninstalling google-pasta-0.2.0:\n",
      "      Successfully uninstalled google-pasta-0.2.0\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.2.2\n",
      "    Uninstalling gast-0.2.2:\n",
      "      Successfully uninstalled gast-0.2.2\n",
      "  Attempting uninstall: astor\n",
      "    Found existing installation: astor 0.8.1\n",
      "    Uninstalling astor-0.8.1:\n",
      "      Successfully uninstalled astor-0.8.1\n",
      "  Attempting uninstall: tensorflow-gpu\n",
      "    Found existing installation: tensorflow-gpu 1.15.0\n",
      "    Uninstalling tensorflow-gpu-1.15.0:\n",
      "      Successfully uninstalled tensorflow-gpu-1.15.0\n",
      "Successfully installed absl-py-0.12.0 astor-0.8.1 cached-property-1.5.2 gast-0.2.2 google-pasta-0.2.0 grpcio-1.38.0 h5py-3.2.1 importlib-metadata-4.5.0 keras-applications-1.0.8 keras-preprocessing-1.1.2 markdown-3.3.4 numpy-1.20.3 opt-einsum-3.3.0 protobuf-3.17.3 setuptools-57.0.0 six-1.16.0 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0 termcolor-1.1.0 typing-extensions-3.10.0.0 werkzeug-2.0.1 wheel-0.36.2 wrapt-1.12.1 zipp-3.4.1\n",
      "Collecting numpy==1.19.0\n",
      "  Using cached numpy-1.19.0-cp37-cp37m-win_amd64.whl (13.0 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.3\n",
      "    Uninstalling numpy-1.20.3:\n",
      "      Successfully uninstalled numpy-1.20.3\n",
      "Successfully installed numpy-1.19.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install --user -U tensorflow-gpu==1.15.0 --force-reinstall \n",
    "!pip install -U --user numpy==1.19.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guided Annotation tool - LSTM\n",
    "This notebook shows you the whole process of preparing the data which is used as input in the guided annotation tool.\n",
    "The tool basically shows unlabelled data in the form of explainable clusters to label.\n",
    "It will show you the following steps:\n",
    "\n",
    "    1. Load dataset\n",
    "    2. Train a model and explain it - LSTM in this case\n",
    "    3. Perform shap clustering\n",
    "    4. Save the clusters to database with keywords to be highlighted by the annotation tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "files = os.listdir(\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.0/bin\")\n",
    "files = [i for i in files if i.endswith('.dll') and i.startswith('cu')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "for file in files:\n",
    "    try:\n",
    "        hllDll = ctypes.WinDLL(\"C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v10.0\\\\bin\\\\\"+ file)\n",
    "    except:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H03PlCG_r3Rb"
   },
   "source": [
    "## 1. Install dependencies and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "GFyqprpNravi"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean, cosine\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, homogeneity_score, v_measure_score, completeness_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "# import chart_studio.plotly as py\n",
    "import seaborn as sns\n",
    "import shap\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, homogeneity_score\n",
    "\n",
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RqlY7kSZsR_J",
    "outputId": "d8b9723a-77c7-45a9-c76e-02760290b38f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6018178429046417338\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3186409472\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17738458457878296517\n",
      "physical_device_desc: \"device: 0, name: Quadro M1200, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built-in function usage\n",
    "To avoid re-writing a lot of stuff for each dataset/model, I have created some functions in the models module/folder.\n",
    "We are going to use this python module in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WsnVbnVSrfeJ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir('../')\n",
    "from models.trainers import Trainer\n",
    "from app.utils import clear_labels\n",
    "from models.guided_learning import GuidedLearner\n",
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvHDTx82sHvq"
   },
   "source": [
    "## 2.Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "B3jcMyakrp_J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5233, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>as a woman you should not complain about cleaning up your house as a man you should always take the garbage out</td>\n",
       "      <td>as a woman you should not complain about cleaning up your house as a man you should always take the garbage out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>momma said no cats inside my doghouse</td>\n",
       "      <td>momma said no cats inside my doghouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>simply addicted to guys hot scally lad</td>\n",
       "      <td>simply addicted to guys hot scally lad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>and hot soles</td>\n",
       "      <td>and hot soles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>lemmie eat a oreo do these dishes one oreo</td>\n",
       "      <td>lemmie eat a oreo do these dishes one oreo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>why the eggplant emoji would he say she looked like scream</td>\n",
       "      <td>why the eggplant emoji would he say she looked like scream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>baby monkey bathtime this is so adorable</td>\n",
       "      <td>baby monkey bathtime this is so adorable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>baseball season for the win yankees this is where the love started</td>\n",
       "      <td>baseball season for the win yankees this is where the love started</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>i am an early bird and i am a night owl so i am wise and have worms</td>\n",
       "      <td>i am an early bird and i am a night owl so i am wise and have worms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>overdosing on heavy drugs does not sound bad tonight i do that every day</td>\n",
       "      <td>overdosing on heavy drugs does not sound bad tonight i do that every day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  label                                                                                                               text                                                                                                          processed\n",
       "0      1      0   as a woman you should not complain about cleaning up your house as a man you should always take the garbage out    as a woman you should not complain about cleaning up your house as a man you should always take the garbage out \n",
       "1      2      0                                                                             momma said no cats inside my doghouse                                                                              momma said no cats inside my doghouse \n",
       "2      3      0                                                                             simply addicted to guys hot scally lad                                                                             simply addicted to guys hot scally lad\n",
       "3      4      0                                                                                                      and hot soles                                                                                                      and hot soles\n",
       "4      5      0                                                                        lemmie eat a oreo do these dishes one oreo                                                                         lemmie eat a oreo do these dishes one oreo \n",
       "5      6      0                                                        why the eggplant emoji would he say she looked like scream                                                         why the eggplant emoji would he say she looked like scream \n",
       "6      7      0                                                                          baby monkey bathtime this is so adorable                                                                           baby monkey bathtime this is so adorable \n",
       "7      8      0                                                 baseball season for the win yankees this is where the love started                                                 baseball season for the win yankees this is where the love started\n",
       "8      9      0                                               i am an early bird and i am a night owl so i am wise and have worms                                                i am an early bird and i am a night owl so i am wise and have worms \n",
       "9     10      0                                          overdosing on heavy drugs does not sound bad tonight i do that every day                                           overdosing on heavy drugs does not sound bad tonight i do that every day "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/davidson_dataset.csv') # substitute other datasets in similar format\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0tTcVlV1rwoJ",
    "outputId": "448a8039-9b0b-4add-97f7-3727517c6544"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3857\n",
       "1    1376\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzw2xqxJs_lz"
   },
   "source": [
    "## 3. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8OESMUtItWIp"
   },
   "outputs": [],
   "source": [
    "x = df['text'].values\n",
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Rzq02FrLtb8b"
   },
   "outputs": [],
   "source": [
    "indices =  np.random.randint(low=0, high=x.shape[0], size=x.shape[0])\n",
    "train_indices = indices[0:round(0.8*x.shape[0])]\n",
    "pool_indices = indices[round(0.8*x.shape[0]):]\n",
    "df_train = df.iloc[train_indices]['text'].values\n",
    "df_test = df.iloc[pool_indices]['text'].values\n",
    "y_train = y[train_indices]\n",
    "y_test = y[pool_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VIHdozZSuVia",
    "outputId": "80d157d5-31f7-4f72-be31-c45f0f61667d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " albert you pulled that queer shit as spon as you put no homo \n",
      "[2642, 4, 702, 11, 220, 175, 56, 2643, 56, 4, 198, 40, 703]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(df_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(df_train)\n",
    "X_test = tokenizer.texts_to_sequences(df_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "print(df_train[2])\n",
    "print(X_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "path_to_glove_file = \"notebooks/glove.6B.300d.txt\"\n",
    "\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file, encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mrA8ODLAr0cq",
    "outputId": "ba78a77c-3810-4e2a-c710-2ba495826657"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "4186 train sequences\n",
      "1047 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (4186, 80)\n",
      "x_test shape: (1047, 80)\n",
      "Build model...\n",
      "WARNING:tensorflow:From C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 4186 samples, validate on 1047 samples\n",
      "Epoch 1/5\n",
      "4186/4186 [==============================] - 160s 38ms/sample - loss: 0.2579 - acc: 0.8966 - val_loss: 0.0945 - val_acc: 0.9694\n",
      "Epoch 2/5\n",
      "4186/4186 [==============================] - 155s 37ms/sample - loss: 0.0589 - acc: 0.9818 - val_loss: 0.1067 - val_acc: 0.9685\n",
      "Epoch 3/5\n",
      "4186/4186 [==============================] - 151s 36ms/sample - loss: 0.0218 - acc: 0.9928 - val_loss: 0.1055 - val_acc: 0.9771\n",
      "Epoch 4/5\n",
      "4186/4186 [==============================] - 213s 51ms/sample - loss: 0.0110 - acc: 0.9967 - val_loss: 0.1113 - val_acc: 0.9790\n",
      "Epoch 5/5\n",
      "4186/4186 [==============================] - 214s 51ms/sample - loss: 0.0030 - acc: 0.9990 - val_loss: 0.1444 - val_acc: 0.9761\n",
      "1047/1047 [==============================] - 10s 9ms/sample - loss: 0.1444 - acc: 0.9761\n",
      "Test score: 0.14439291991450695\n",
      "Test accuracy: 0.97612226\n"
     ]
    }
   ],
   "source": [
    "max_features = vocab_size\n",
    "maxlen = 80  # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 4\n",
    "n_epochs = 5\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = (X_train, y_train), (X_test, y_test)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "x_train = np.asarray(x_train).astype(np.float32)\n",
    "y_train =np.asarray(y_train).astype(np.float32)\n",
    "x_test =np.asarray(x_test).astype(np.float32)\n",
    "y_test =np.asarray(y_test).astype(np.float32)\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 128))\n",
    "model.add(LSTM(128, dropout=0.4, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "history  = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=n_epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBlQIIMg0Ofp"
   },
   "outputs": [],
   "source": [
    "# Plot epochs vs train and test scores\n",
    "# data = [go.Scatter(x=list(range(n_epochs)), y=homogeneity_scores, mode=\"lines\", name=\"homogeneity\"),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "X23BkFG6hQ_h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1047/1047 [==============================] - 2s 2ms/sample\n",
      "Overall F1 Score 0.9576988155668359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = model.predict_classes(x_test, verbose=1)\n",
    "print('Overall F1 Score', f1_score(predictions, y_test))\n",
    "sns.heatmap(confusion_matrix(y_test, predictions),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4186, 80), (1047, 80))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Perform shap clustering\n",
    "We are going to cluster the training data using SHAP explanations (shapely space)\n",
    "SHAP clustering works by clustering on Shapley values of each instance. \n",
    "This means that you cluster instances by explanation similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "FJzb5Dcau3uS"
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# we use the first 100 training examples as our background dataset to integrate over\n",
    "explainer = shap.DeepExplainer(model, x_train[:5000])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[80,8372,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node lstm/TensorArrayStack/TensorArrayGatherV3 (defined at C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[gradients_1/embedding/embedding_lookup_grad/Select/_131]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[80,8372,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node lstm/TensorArrayStack/TensorArrayGatherV3 (defined at C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'lstm/TensorArrayStack/TensorArrayGatherV3':\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n    app.start()\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 619, in start\n    self.io_loop.start()\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 374, in dispatch_queue\n    yield self.process_one()\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\gen.py\", line 250, in wrapper\n    runner = Runner(ctx_run, result, future, yielded)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\gen.py\", line 741, in __init__\n    self.ctx_run(self.run)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 358, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 261, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 538, in execute_request\n    user_expressions, allow_stdin,\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 302, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 539, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2899, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2944, in _run_cell\n    return runner(coro)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3170, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3441, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-cec2411107a9>\", line 22, in <module>\n    model.add(LSTM(128, dropout=0.4, recurrent_dropout=0.2))\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\", line 457, in _method_wrapper\n    result = method(self, *args, **kwargs)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\", line 195, in add\n    output_tensor = layer(self.outputs[0])\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\", line 623, in __call__\n    return super(RNN, self).__call__(inputs, **kwargs)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\", line 854, in __call__\n    outputs = call_fn(cast_inputs, *args, **kwargs)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\", line 2549, in call\n    inputs, mask=mask, training=training, initial_state=initial_state)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\", line 756, in call\n    zero_output_for_mask=self.zero_output_for_mask)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 4057, in rnn\n    outputs = tuple(o.stack() for o in output_ta)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 4057, in <genexpr>\n    outputs = tuple(o.stack() for o in output_ta)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\tensor_array_ops.py\", line 1098, in stack\n    return self._implementation.stack(name=name)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\tensor_array_ops.py\", line 283, in stack\n    return self.gather(math_ops.range(0, self.size()), name=name)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\tensor_array_ops.py\", line 297, in gather\n    element_shape=element_shape)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\gen_data_flow_ops.py\", line 7103, in tensor_array_gather_v3\n    element_shape=element_shape, name=name)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[80,8372,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node lstm/TensorArrayStack/TensorArrayGatherV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[gradients_1/embedding/embedding_lookup_grad/Select/_131]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[80,8372,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node lstm/TensorArrayStack/TensorArrayGatherV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-83cec6347e53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# explain the first 10 predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# explaining each prediction requires 2 * background dataset size runs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mshap_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\shap\\explainers\\_deep\\__init__.py\u001b[0m in \u001b[0;36mshap_values\u001b[1;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[0mwere\u001b[0m \u001b[0mchosen\u001b[0m \u001b[1;32mas\u001b[0m \u001b[1;34m\"top\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \"\"\"\n\u001b[1;32m--> 124\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mranked_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_rank_order\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_additivity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_additivity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\u001b[0m in \u001b[0;36mshap_values\u001b[1;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[0;32m    306\u001b[0m                 \u001b[1;31m# run attribution computation graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m                 \u001b[0mfeature_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_output_ranks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m                 \u001b[0msample_phis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphi_symbolic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_ind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjoint_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 \u001b[1;31m# assign the attributions to the right part of the output arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, out, model_inputs, X)\u001b[0m\n\u001b[0;32m    346\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_phase_flags\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m                 \u001b[0mfeed_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0manon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                     \u001b[1;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[1;32m-> 1384\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[80,8372,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node lstm/TensorArrayStack/TensorArrayGatherV3 (defined at C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[gradients_1/embedding/embedding_lookup_grad/Select/_131]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[80,8372,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node lstm/TensorArrayStack/TensorArrayGatherV3 (defined at C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'lstm/TensorArrayStack/TensorArrayGatherV3':\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n    app.start()\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 619, in start\n    self.io_loop.start()\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 374, in dispatch_queue\n    yield self.process_one()\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\gen.py\", line 250, in wrapper\n    runner = Runner(ctx_run, result, future, yielded)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\gen.py\", line 741, in __init__\n    self.ctx_run(self.run)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 358, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 261, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 538, in execute_request\n    user_expressions, allow_stdin,\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 302, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 539, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2899, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2944, in _run_cell\n    return runner(coro)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3170, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3441, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-cec2411107a9>\", line 22, in <module>\n    model.add(LSTM(128, dropout=0.4, recurrent_dropout=0.2))\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\", line 457, in _method_wrapper\n    result = method(self, *args, **kwargs)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\", line 195, in add\n    output_tensor = layer(self.outputs[0])\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\", line 623, in __call__\n    return super(RNN, self).__call__(inputs, **kwargs)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\", line 854, in __call__\n    outputs = call_fn(cast_inputs, *args, **kwargs)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\", line 2549, in call\n    inputs, mask=mask, training=training, initial_state=initial_state)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\", line 756, in call\n    zero_output_for_mask=self.zero_output_for_mask)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 4057, in rnn\n    outputs = tuple(o.stack() for o in output_ta)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 4057, in <genexpr>\n    outputs = tuple(o.stack() for o in output_ta)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\tensor_array_ops.py\", line 1098, in stack\n    return self._implementation.stack(name=name)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\tensor_array_ops.py\", line 283, in stack\n    return self.gather(math_ops.range(0, self.size()), name=name)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\tensor_array_ops.py\", line 297, in gather\n    element_shape=element_shape)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\gen_data_flow_ops.py\", line 7103, in tensor_array_gather_v3\n    element_shape=element_shape, name=name)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "# explain the first 10 predictions\n",
    "# explaining each prediction requires 2 * background dataset size runs\n",
    "shap_values = explainer.shap_values(x_test[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VMDQvNvujQoC"
   },
   "outputs": [],
   "source": [
    "shap_values[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vhUfBh-eu8EZ"
   },
   "outputs": [],
   "source": [
    "# Creating a reverse dictionary\n",
    "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
    "shap.summary_plot(shap_values[0], x_test[:100], reverse_word_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RFsZeKfhV9vo"
   },
   "outputs": [],
   "source": [
    "# transform the indexes to words\n",
    "import numpy as np\n",
    "# use number to words map to get x_test in form of words\n",
    "num2word = reverse_word_map\n",
    "x_test_words = np.stack([np.array(list(map(lambda x: num2word.get(x, \"NONE\"), x_test[i]))) for i in range(10)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "khMZ7IAnzkg-"
   },
   "outputs": [],
   "source": [
    "index = 1\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0][index], x_test_words[index], matplotlib=True), df_test[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nPBBVMFzzwD2"
   },
   "outputs": [],
   "source": [
    "shap_values_pool = shap_values[0]\n",
    "n_clusters = 20\n",
    "kmeans = KMeans(n_clusters= n_clusters, n_jobs=-1, max_iter=600)\n",
    "kmeans.fit(shap_values_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XdS4wzfZbwHW"
   },
   "outputs": [],
   "source": [
    "homogeneity_score( y_test[:1000], kmeans.labels_), v_measure_score(y_test[:1000], kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A0DURnPPb7ZG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Hate_xplain_shap.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
