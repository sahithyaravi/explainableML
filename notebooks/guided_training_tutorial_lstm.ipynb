{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "J5P4ugEmiS8G",
    "outputId": "e42ab5c2-a0f4-4db4-a84d-bd1ea21fd32a"
   },
   "outputs": [],
   "source": [
    "!pip install --user -U tensorflow-gpu==1.15.0 --force-reinstall \n",
    "!pip install -U --user numpy==1.19.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guided Annotation tool - LSTM\n",
    "This notebook shows you the whole process of preparing the data which is used as input in the guided annotation tool.\n",
    "The tool basically shows unlabelled data in the form of explainable clusters to label.\n",
    "It will show you the following steps:\n",
    "\n",
    "    1. Load dataset\n",
    "    2. Train a model and explain it - LSTM in this case\n",
    "    3. Perform shap clustering\n",
    "    4. Save the clusters to database with keywords to be highlighted by the annotation tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "files = os.listdir(\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.0/bin\")\n",
    "files = [i for i in files if i.endswith('.dll') and i.startswith('cu')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "for file in files:\n",
    "    try:\n",
    "        hllDll = ctypes.WinDLL(\"C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v10.0\\\\bin\\\\\"+ file)\n",
    "    except:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H03PlCG_r3Rb"
   },
   "source": [
    "## 1. Install dependencies and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "GFyqprpNravi"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean, cosine\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, homogeneity_score, v_measure_score, completeness_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "# import chart_studio.plotly as py\n",
    "import seaborn as sns\n",
    "import shap\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, homogeneity_score\n",
    "\n",
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RqlY7kSZsR_J",
    "outputId": "d8b9723a-77c7-45a9-c76e-02760290b38f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1252783600176548313\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3186409472\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 1819469729116961709\n",
      "physical_device_desc: \"device: 0, name: Quadro M1200, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built-in function usage\n",
    "To avoid re-writing a lot of stuff for each dataset/model, I have created some functions in the models module/folder.\n",
    "We are going to use this python module in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WsnVbnVSrfeJ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir('../')\n",
    "from models.trainers import Trainer\n",
    "from app.utils import clear_labels\n",
    "from models.guided_learning import GuidedLearner\n",
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvHDTx82sHvq"
   },
   "source": [
    "## 2.Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "B3jcMyakrp_J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5233, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>as a woman you should not complain about cleaning up your house as a man you should always take the garbage out</td>\n",
       "      <td>as a woman you should not complain about cleaning up your house as a man you should always take the garbage out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>momma said no cats inside my doghouse</td>\n",
       "      <td>momma said no cats inside my doghouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>simply addicted to guys hot scally lad</td>\n",
       "      <td>simply addicted to guys hot scally lad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>and hot soles</td>\n",
       "      <td>and hot soles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>lemmie eat a oreo do these dishes one oreo</td>\n",
       "      <td>lemmie eat a oreo do these dishes one oreo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>why the eggplant emoji would he say she looked like scream</td>\n",
       "      <td>why the eggplant emoji would he say she looked like scream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>baby monkey bathtime this is so adorable</td>\n",
       "      <td>baby monkey bathtime this is so adorable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>baseball season for the win yankees this is where the love started</td>\n",
       "      <td>baseball season for the win yankees this is where the love started</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>i am an early bird and i am a night owl so i am wise and have worms</td>\n",
       "      <td>i am an early bird and i am a night owl so i am wise and have worms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>overdosing on heavy drugs does not sound bad tonight i do that every day</td>\n",
       "      <td>overdosing on heavy drugs does not sound bad tonight i do that every day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  label                                                                                                               text                                                                                                          processed\n",
       "0      1      0   as a woman you should not complain about cleaning up your house as a man you should always take the garbage out    as a woman you should not complain about cleaning up your house as a man you should always take the garbage out \n",
       "1      2      0                                                                             momma said no cats inside my doghouse                                                                              momma said no cats inside my doghouse \n",
       "2      3      0                                                                             simply addicted to guys hot scally lad                                                                             simply addicted to guys hot scally lad\n",
       "3      4      0                                                                                                      and hot soles                                                                                                      and hot soles\n",
       "4      5      0                                                                        lemmie eat a oreo do these dishes one oreo                                                                         lemmie eat a oreo do these dishes one oreo \n",
       "5      6      0                                                        why the eggplant emoji would he say she looked like scream                                                         why the eggplant emoji would he say she looked like scream \n",
       "6      7      0                                                                          baby monkey bathtime this is so adorable                                                                           baby monkey bathtime this is so adorable \n",
       "7      8      0                                                 baseball season for the win yankees this is where the love started                                                 baseball season for the win yankees this is where the love started\n",
       "8      9      0                                               i am an early bird and i am a night owl so i am wise and have worms                                                i am an early bird and i am a night owl so i am wise and have worms \n",
       "9     10      0                                          overdosing on heavy drugs does not sound bad tonight i do that every day                                           overdosing on heavy drugs does not sound bad tonight i do that every day "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/davidson_dataset.csv') # substitute other datasets in similar format\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0tTcVlV1rwoJ",
    "outputId": "448a8039-9b0b-4add-97f7-3727517c6544"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3857\n",
       "1    1376\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzw2xqxJs_lz"
   },
   "source": [
    "## 3. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8OESMUtItWIp"
   },
   "outputs": [],
   "source": [
    "x = df['text'].values\n",
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Rzq02FrLtb8b"
   },
   "outputs": [],
   "source": [
    "indices =  np.random.randint(low=0, high=x.shape[0], size=x.shape[0])\n",
    "train_indices = indices[0:round(0.8*x.shape[0])]\n",
    "pool_indices = indices[round(0.8*x.shape[0]):]\n",
    "df_train = df.iloc[train_indices]['text'].values\n",
    "df_test = df.iloc[pool_indices]['text'].values\n",
    "y_train = y[train_indices]\n",
    "y_test = y[pool_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VIHdozZSuVia",
    "outputId": "80d157d5-31f7-4f72-be31-c45f0f61667d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the birds and the bugs \n",
      "[1, 59, 7, 1, 2607]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(df_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(df_train)\n",
    "X_test = tokenizer.texts_to_sequences(df_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "print(df_train[2])\n",
    "print(X_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "path_to_glove_file = \"notebooks/glove.6B.300d.txt\" #download glove embeddings\n",
    "\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file, encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mrA8ODLAr0cq",
    "outputId": "ba78a77c-3810-4e2a-c710-2ba495826657"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "4186 train sequences\n",
      "1047 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (4186, 80)\n",
      "x_test shape: (1047, 80)\n",
      "Build model...\n",
      "WARNING:tensorflow:From C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 4186 samples, validate on 1047 samples\n",
      "Epoch 1/2\n",
      "4186/4186 [==============================] - 805s 192ms/sample - loss: 0.2412 - acc: 0.9142 - val_loss: 0.1053 - val_acc: 0.9647\n",
      "Epoch 2/2\n",
      "4186/4186 [==============================] - 921s 220ms/sample - loss: 0.0547 - acc: 0.9838 - val_loss: 0.0804 - val_acc: 0.9742\n",
      "1047/1047 [==============================] - 44s 42ms/sample - loss: 0.0804 - acc: 0.9742\n",
      "Test score: 0.08036523470201067\n",
      "Test accuracy: 0.97421205\n"
     ]
    }
   ],
   "source": [
    "max_features = vocab_size\n",
    "maxlen = 80  # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 1\n",
    "n_epochs = 2\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = (X_train, y_train), (X_test, y_test)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "x_train = np.asarray(x_train).astype(np.float32)\n",
    "y_train =np.asarray(y_train).astype(np.float32)\n",
    "x_test =np.asarray(x_test).astype(np.float32)\n",
    "y_test =np.asarray(y_test).astype(np.float32)\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 128))\n",
    "model.add(LSTM(128, dropout=0.4, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "history  = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=n_epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBlQIIMg0Ofp"
   },
   "outputs": [],
   "source": [
    "# Plot epochs vs train and test scores\n",
    "# data = [go.Scatter(x=list(range(n_epochs)), y=homogeneity_scores, mode=\"lines\", name=\"homogeneity\"),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "X23BkFG6hQ_h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1047/1047 [==============================] - 1s 1ms/sample\n",
      "Overall F1 Score 0.9515260323159783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = model.predict_classes(x_test, verbose=1)\n",
    "print('Overall F1 Score', f1_score(predictions, y_test))\n",
    "sns.heatmap(confusion_matrix(y_test, predictions),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4186, 80), (1047, 80))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Perform shap clustering\n",
    "We are going to cluster the training data using SHAP explanations (shapely space)\n",
    "SHAP clustering works by clustering on Shapley values of each instance. \n",
    "This means that you cluster instances by explanation similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "FJzb5Dcau3uS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\shap\\explainers\\tf_utils.py:28: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\shap\\explainers\\tf_utils.py:28: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "# we use the first 100 training examples as our background dataset to integrate over\n",
    "explainer = shap.DeepExplainer(model, x_train[:2000])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[80,4000,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node lstm/TensorArrayStack/TensorArrayGatherV3 (defined at C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[gradients/embedding/embedding_lookup_grad/Select/_125]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[80,4000,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node lstm/TensorArrayStack/TensorArrayGatherV3 (defined at C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'lstm/TensorArrayStack/TensorArrayGatherV3':\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n    app.start()\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 619, in start\n    self.io_loop.start()\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 374, in dispatch_queue\n    yield self.process_one()\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\gen.py\", line 250, in wrapper\n    runner = Runner(ctx_run, result, future, yielded)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\gen.py\", line 741, in __init__\n    self.ctx_run(self.run)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 358, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 261, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 538, in execute_request\n    user_expressions, allow_stdin,\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 302, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 539, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2899, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2944, in _run_cell\n    return runner(coro)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3170, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3441, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-f6da5bdea329>\", line 22, in <module>\n    model.add(LSTM(128, dropout=0.4, recurrent_dropout=0.2))\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\", line 457, in _method_wrapper\n    result = method(self, *args, **kwargs)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\", line 195, in add\n    output_tensor = layer(self.outputs[0])\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\", line 623, in __call__\n    return super(RNN, self).__call__(inputs, **kwargs)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\", line 854, in __call__\n    outputs = call_fn(cast_inputs, *args, **kwargs)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\", line 2549, in call\n    inputs, mask=mask, training=training, initial_state=initial_state)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\", line 756, in call\n    zero_output_for_mask=self.zero_output_for_mask)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 4057, in rnn\n    outputs = tuple(o.stack() for o in output_ta)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 4057, in <genexpr>\n    outputs = tuple(o.stack() for o in output_ta)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\tensor_array_ops.py\", line 1098, in stack\n    return self._implementation.stack(name=name)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\tensor_array_ops.py\", line 283, in stack\n    return self.gather(math_ops.range(0, self.size()), name=name)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\tensor_array_ops.py\", line 297, in gather\n    element_shape=element_shape)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\gen_data_flow_ops.py\", line 7103, in tensor_array_gather_v3\n    element_shape=element_shape, name=name)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[80,4000,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node lstm/TensorArrayStack/TensorArrayGatherV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[gradients/embedding/embedding_lookup_grad/Select/_125]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[80,4000,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node lstm/TensorArrayStack/TensorArrayGatherV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-83cec6347e53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# explain the first 10 predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# explaining each prediction requires 2 * background dataset size runs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mshap_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\shap\\explainers\\_deep\\__init__.py\u001b[0m in \u001b[0;36mshap_values\u001b[1;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[0mwere\u001b[0m \u001b[0mchosen\u001b[0m \u001b[1;32mas\u001b[0m \u001b[1;34m\"top\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \"\"\"\n\u001b[1;32m--> 124\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mranked_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_rank_order\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_additivity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_additivity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\u001b[0m in \u001b[0;36mshap_values\u001b[1;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[0;32m    306\u001b[0m                 \u001b[1;31m# run attribution computation graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m                 \u001b[0mfeature_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_output_ranks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m                 \u001b[0msample_phis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphi_symbolic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_ind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjoint_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 \u001b[1;31m# assign the attributions to the right part of the output arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, out, model_inputs, X)\u001b[0m\n\u001b[0;32m    346\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_phase_flags\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m                 \u001b[0mfeed_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0manon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                     \u001b[1;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[1;32m-> 1384\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted: OOM when allocating tensor with shape[80,4000,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node lstm/TensorArrayStack/TensorArrayGatherV3 (defined at C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[gradients/embedding/embedding_lookup_grad/Select/_125]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted: OOM when allocating tensor with shape[80,4000,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node lstm/TensorArrayStack/TensorArrayGatherV3 (defined at C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored.\n\nOriginal stack trace for 'lstm/TensorArrayStack/TensorArrayGatherV3':\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n    app.start()\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 619, in start\n    self.io_loop.start()\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\asyncio\\events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 374, in dispatch_queue\n    yield self.process_one()\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\gen.py\", line 250, in wrapper\n    runner = Runner(ctx_run, result, future, yielded)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\gen.py\", line 741, in __init__\n    self.ctx_run(self.run)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 358, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 261, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 538, in execute_request\n    user_expressions, allow_stdin,\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 302, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 539, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2899, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2944, in _run_cell\n    return runner(coro)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3170, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"c:\\users\\s164255\\anaconda3\\envs\\explainableml\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3441, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-f6da5bdea329>\", line 22, in <module>\n    model.add(LSTM(128, dropout=0.4, recurrent_dropout=0.2))\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\", line 457, in _method_wrapper\n    result = method(self, *args, **kwargs)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\", line 195, in add\n    output_tensor = layer(self.outputs[0])\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\", line 623, in __call__\n    return super(RNN, self).__call__(inputs, **kwargs)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\", line 854, in __call__\n    outputs = call_fn(cast_inputs, *args, **kwargs)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\", line 2549, in call\n    inputs, mask=mask, training=training, initial_state=initial_state)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\layers\\recurrent.py\", line 756, in call\n    zero_output_for_mask=self.zero_output_for_mask)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 4057, in rnn\n    outputs = tuple(o.stack() for o in output_ta)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 4057, in <genexpr>\n    outputs = tuple(o.stack() for o in output_ta)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\tensor_array_ops.py\", line 1098, in stack\n    return self._implementation.stack(name=name)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\tensor_array_ops.py\", line 283, in stack\n    return self.gather(math_ops.range(0, self.size()), name=name)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\tensor_array_ops.py\", line 297, in gather\n    element_shape=element_shape)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\gen_data_flow_ops.py\", line 7103, in tensor_array_gather_v3\n    element_shape=element_shape, name=name)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"C:\\Users\\s164255\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "# explain the first 10 predictions\n",
    "# explaining each prediction requires 2 * background dataset size runs\n",
    "shap_values = explainer.shap_values(x_test[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VMDQvNvujQoC"
   },
   "outputs": [],
   "source": [
    "shap_values[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vhUfBh-eu8EZ"
   },
   "outputs": [],
   "source": [
    "# Creating a reverse dictionary\n",
    "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
    "shap.summary_plot(shap_values[0], x_test[:100], reverse_word_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RFsZeKfhV9vo"
   },
   "outputs": [],
   "source": [
    "# transform the indexes to words\n",
    "import numpy as np\n",
    "# use number to words map to get x_test in form of words\n",
    "num2word = reverse_word_map\n",
    "x_test_words = np.stack([np.array(list(map(lambda x: num2word.get(x, \"NONE\"), x_test[i]))) for i in range(10)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "khMZ7IAnzkg-"
   },
   "outputs": [],
   "source": [
    "index = 1\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0][index], x_test_words[index], matplotlib=True), df_test[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nPBBVMFzzwD2"
   },
   "outputs": [],
   "source": [
    "shap_values_pool = shap_values[0]\n",
    "n_clusters = 20\n",
    "kmeans = KMeans(n_clusters= n_clusters, n_jobs=-1, max_iter=600)\n",
    "kmeans.fit(shap_values_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XdS4wzfZbwHW"
   },
   "outputs": [],
   "source": [
    "homogeneity_score( y_test[:1000], kmeans.labels_), v_measure_score(y_test[:1000], kmeans.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A0DURnPPb7ZG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Hate_xplain_shap.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
