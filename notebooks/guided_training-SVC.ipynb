{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean, cosine\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, homogeneity_score, v_measure_score, completeness_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import chart_studio.plotly as py\n",
    "import seaborn as sns\n",
    "import shap\n",
    "\n",
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/gao_dataset.csv')\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['text'].values\n",
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word representation\n",
    "We are going to use TF*IDF (Term frequency- Inverse document frequency) vectorizer to convert our text into numbers.\n",
    "\n",
    "TF = Frequency of term\n",
    "\n",
    "IDF = No of docs/ No of docs with the term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid = TfidfVectorizer(max_features=500)\n",
    "x = tfid.fit_transform(x).toarray()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting data\n",
    "  We split data into training, test and pool. Pool is the unlabelled pool we want to generate SHAP clusters for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "indices =  np.random.randint(low=0, high=x.shape[0], size=x.shape[0])\n",
    "train_indices = indices[0:round(0.6*x.shape[0])]\n",
    "test_indices = indices[round(0.6*x.shape[0]): round(0.7*x.shape[0])]\n",
    "pool_indices = indices[round(0.7*x.shape[0]):]\n",
    "df_train = df.iloc[train_indices]['text'].values\n",
    "df_test = df.iloc[test_indices]['text'].values\n",
    "df_pool = df.iloc[pool_indices]['text'].values\n",
    "x_train = x[train_indices]\n",
    "y_train = y[train_indices]\n",
    "x_test = x[test_indices]\n",
    "y_test = y[test_indices]\n",
    "x_pool = x[pool_indices]\n",
    "y_pool = y[pool_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model fitting\n",
    "We do a simple grid search to find the best SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_iter=1000\n",
    "C= [0.5, 1, 2]\n",
    "best_f1 = 0\n",
    "model = None\n",
    "for c in C:\n",
    "    m = SVC( max_iter=max_iter, C=c, kernel='linear', class_weight='balanced', probability=True)\n",
    "    m.fit(x_train, y_train)\n",
    "    m.score(x_train,y_train)\n",
    "    predictions = m.predict(x_test)\n",
    "    f1 = f1_score(predictions, y_test)\n",
    "    if  f1 > best_f1:\n",
    "        model = m\n",
    "        best_f1 = f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We measure the f1_score and plot confusion matrix. Recall:\n",
    "- f1 score = 2PR/ (P+R)\n",
    "- Precision = actual positives/ predicted positives\n",
    "- Recall = predicted positives/ total actual positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_pool)\n",
    "f1_score(predictions, y_pool), accuracy_score(y_pool, predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert predict probability to uncertainty. In binary classification this would be the same as 1-P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classwise_uncertainty = model.predict_proba(x_pool)\n",
    "uncertainty = 1 - np.max(classwise_uncertainty, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(uncertainty)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(confusion_matrix(y_pool, predictions),annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explain model using SHAP\n",
    "\n",
    "Refer https://christophm.github.io/interpretable-ml-book/shap.html\n",
    "\n",
    "The goal of SHAP is to explain the prediction of an instance x by computing the contribution of each feature to the prediction. The SHAP explanation method computes Shapley values from coalitional game theory. The feature values of a data instance act as players in a coalition. Shapley values tell us how to fairly distribute the “payout” (= the prediction) among the features\n",
    "\n",
    "We call the SHAP explainer for linear models\n",
    "shapely values produced have same dimensions as data passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.LinearExplainer(model, x_train,feature_dependence=\"independent\")\n",
    "shap_values_train = explainer.shap_values(x_train)\n",
    "shap_values_pool = explainer.shap_values(x_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain a single positive prediction at 'index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postive_index = 10\n",
    "index = np.where(predictions==1)[0][postive_index]\n",
    "print(\"text \", df_test[index], \" prediction: \", predictions[index], \"actual \", y_test[index])\n",
    "shap.force_plot(explainer.expected_value, \n",
    "                               shap_values_pool[index,:], \n",
    "                               x_test[index,:], feature_names = tfid.get_feature_names(),\n",
    "               matplotlib=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain the overall feature importance using summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values_pool, x_pool, feature_names=tfid.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_pool.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering data\n",
    "We are going to cluster the training data using SHAP explanations (shapely space)\n",
    "SHAP clustering works by clustering on Shapley values of each instance. \n",
    "This means that you cluster instances by explanation similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 20\n",
    "kmeans = KMeans(n_clusters= n_clusters, n_jobs=-1, max_iter=600)\n",
    "kmeans.fit(shap_values_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homogeneity_score( y_pool, kmeans.labels_), v_measure_score(y_pool, kmeans.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use cosine distance instead of euclidean distance to measure the similarity between the documents.\n",
    "As the size of the document increases, the number of common words (euclidean) tend to increase \n",
    "even if the documents talk about different topics. The cosine similarity helps overcome this fundamental flaw \n",
    "and finds the similarity irrespective of size.\n",
    "\n",
    "https://www.machinelearningplus.com/nlp/cosine-similarity/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find similarity of each point in cluster to its centroid\n",
    "similarity_to_center = []\n",
    "for i, instance in enumerate(shap_values_pool):\n",
    "    cluster_label = kmeans.labels_[i] # cluster of this instance\n",
    "    centroid = kmeans.cluster_centers_[cluster_label] # cluster center of the cluster of that instance\n",
    "    similarity = 1-cosine(instance, centroid) # 1- cosine distance gives similarity\n",
    "    similarity_to_center.append(similarity)\n",
    "    \n",
    "centroid_match = [None]*n_clusters\n",
    "centroid_indices =[None]*n_clusters\n",
    "for i, instance in enumerate(shap_values_pool):\n",
    "    cluster_label = kmeans.labels_[i]     \n",
    "    if centroid_match[cluster_label] is None or similarity_to_center[i] > centroid_match[cluster_label]:\n",
    "        centroid_indices[cluster_label] = i\n",
    "        centroid_match[cluster_label] = similarity_to_center[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2, perplexity=20)\n",
    "principals = tsne.fit_transform(shap_values_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "colorscale = [[0, 'mediumturquoise'], [1, 'salmon']]\n",
    "collect = dict()\n",
    "sizes = []\n",
    "color = ['hsl(' + str(h) + ',80%' + ',50%)' for h in np.linspace(0, 255, n_clusters)]\n",
    "df_final_labels = pd.DataFrame()\n",
    "for cluster_id in np.unique(kmeans.labels_):\n",
    "    cluster_indices = np.where(kmeans.labels_ == cluster_id)    \n",
    "    \n",
    "    cluster_text = df_pool[cluster_indices]\n",
    "    center_index = centroid_indices[cluster_id]\n",
    "    center_text = df_pool[center_index]\n",
    "    df_cluster = pd.DataFrame({'text': cluster_text})\n",
    "    df_cluster['cluster_id'] = cluster_id\n",
    "    df_cluster['centroid'] = False\n",
    "    df_cluster = df_cluster.append({'text':center_text, 'cluster_id':cluster_id,\n",
    "                                    'centroid':True }, ignore_index=True)\n",
    "    df_final_labels = pd.concat([df_final_labels, df_cluster])\n",
    "\n",
    "    cp = principals[cluster_indices]\n",
    "    data.append(go.Heatmap(x=cp[:, 0],\n",
    "                           y=cp[:, 1],\n",
    "                           z=uncertainty[cluster_indices],\n",
    "                           name='uncertainity map',\n",
    "                           visible=True,\n",
    "                           showscale=False,\n",
    "                           colorscale=colorscale,\n",
    "                                         ))\n",
    "    data.append(go.Scatter(x = cp[:,0],\n",
    "                   y = cp[:,1],\n",
    "                   mode='markers',                    \n",
    "                hovertext=cluster_text,\n",
    "                            marker=dict(color=color[cluster_id],\n",
    "                                                   size=10),\n",
    "                           name = 'cluster '+ str(cluster_id)\n",
    "                          ))\n",
    "    data.append(go.Scatter(x = [principals[center_index, 0]],\n",
    "                   y = [principals[center_index, 1]],\n",
    "                   mode='markers',  \n",
    "                           marker=dict(color=color[cluster_id],\n",
    "                                                   size=15,\n",
    "                                                   line=dict(color='black', width=5)),\n",
    "                           name = 'centroid cluster '+ str(cluster_id),\n",
    "                           visible='legendonly',\n",
    "                           \n",
    "                          ))\n",
    "    collect[cluster_id] = df_pool[cluster_indices]\n",
    "    \n",
    "fig = go.Figure(data=data)\n",
    "fig.show()\n",
    "df_final_labels.to_csv('df_input.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze uncertainty within clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "ranges = []\n",
    "for cluster_id in np.unique(kmeans.labels_):\n",
    "    cluster_indices = np.where(kmeans.labels_ == cluster_id)    \n",
    "    uncertainty_cluster = uncertainty[cluster_indices]\n",
    "    rng = np.max(uncertainty_cluster)- np.min(uncertainty_cluster)\n",
    "    print(cluster_id, \"range \", rng)\n",
    "    ranges.append(rng)\n",
    "    print(y_pool[cluster_indices])\n",
    "    print(\"\\n\")\n",
    "    data.append(go.Histogram(x=uncertainty_cluster, name=str(cluster_id), showlegend=True,visible='legendonly'))\n",
    "fig = go.Figure(data=data)\n",
    "url=py.plot(fig, filename='clusters_50', sharing='public')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_uncertain_indices = (-uncertainty).argsort()[:20]\n",
    "y_pool[max_uncertain_indices], uncertainty[max_uncertain_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cluster_id = 13\n",
    "cluster_indices = np.where(kmeans.labels_ == cluster_id)    \n",
    "d = {'text' : df_pool[cluster_indices], 'uncertainty': uncertainty[cluster_indices]}\n",
    "\n",
    "pd.DataFrame(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=cluster_indices[0][2]\n",
    "shap.force_plot(explainer.expected_value, shap_values_pool[i,:], x_pool[i,:], feature_names = tfid.get_feature_names(),\n",
    "               matplotlib=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find optimal cluster size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homogeneity_scores = []\n",
    "v_measure_scores = []\n",
    "completeness_scores = []\n",
    "n_iters = 10\n",
    "ranges = list(range(10, 110, 10))\n",
    "for k in ranges:\n",
    "    vavg = 0\n",
    "    havg = 0\n",
    "    cavg = 0\n",
    "    for i in range(n_iters):\n",
    "        kmeans = KMeans(n_clusters= n_clusters, n_jobs=-1)\n",
    "        kmeans.fit(shap_values_pool)\n",
    "        v = v_measure_score(labels_pred=kmeans.labels_, labels_true=y_pool) \n",
    "        h = homogeneity_score(labels_pred=kmeans.labels_, labels_true=y_pool) \n",
    "        c = completeness_score(labels_pred=kmeans.labels_, labels_true=y_pool) \n",
    "        vavg += v\n",
    "        havg += h\n",
    "        cavg += c\n",
    "    homogeneity_scores.append(havg/n_iters)\n",
    "    v_measure_scores.append(vavg/n_iters)\n",
    "    completeness_scores.append(cavg/n_iters)\n",
    "    print(k, \"done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [go.Scatter(x=ranges, y=homogeneity_scores, mode=\"lines\", name=\"homogeneity\"),\n",
    "        go.Scatter(x=ranges, y=v_measure_scores, mode=\"lines\", name=\"v_measure\"),\n",
    "        go.Scatter(x=ranges, y=completeness_scores, mode=\"lines\", name=\"completeness\")\n",
    "        ]\n",
    "fig = go.Figure(data=data)\n",
    "fig.update_layout(xaxis_title=\"no of clusters\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add centroid of each cluster to the training set and retrain the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices_new = np.append(train_indices, centroid_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = SVC( max_iter=max_iter, C=C, kernel='linear')\n",
    "x_train_new = x[train_indices_new]\n",
    "y_train_new = y[train_indices_new]\n",
    "model1.fit(x_train_new, y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.score(x_train_new, y_train_new), model1.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = model1.predict(x_test)\n",
    "f1_score(y_test, predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, predictions1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add entire x_pool back to training instead of just centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices_full = np.append(train_indices, pool_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = SVC(max_iter=max_iter, C=C, kernel='linear')\n",
    "x_train_full = x[train_indices_full]\n",
    "y_train_full = y[train_indices_full]\n",
    "model2.fit(x_train_full, y_train_full)\n",
    "model2.score(x_train_full, y_train_full), model2.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = model2.predict(x_test)\n",
    "f1_score(y_test, predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, predictions2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model with 20% train \", f1_score(y_test, predictions))\n",
    "print(\"Model with 20% train + center \", f1_score(y_test, predictions1))\n",
    "print(\"Model with 20% train + 60% pool \", f1_score(y_test, predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model with 20% train \", accuracy_score(y_test, predictions))\n",
    "print(\"Model with 20% train + center \", accuracy_score(y_test, predictions1))\n",
    "print(\"Model with 20% train + 60% pool \", accuracy_score(y_test, predictions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
